## 4. Evaluation Metrics for Classification

- 4.1 [Evaluation metrics: session overview](01-overview.md)
- 4.2 [Accuracy and dummy model](02-accuracy.md)
- 4.3 [Confusion table](03-confusion-table.md)
- 4.4 [Precision and Recall](04-precision-recall.md)
- 4.5 [ROC Curves](05-roc.md)
- 4.6 [ROC AUC](06-auc.md)
- 4.7 [Cross-Validation](07-cross-validation.md)
- 4.8 [Summary](08-summary.md)
- 4.9 [Explore more](09-explore-more.md)
- 4.10 [Homework](homework.md)

## Community notes

Did you take notes? You can share them here (or in each unit separately)
* [Some cross-validation methods](https://github.com/razekmaiden/ml_zoomcamp/blob/main/additional_topics/ML_ZOOMCAMP_CROSS_VALIDATION_METHODS.ipynb)
* [Notes from Kwang Yang](https://www.kaggle.com/kwangyangchia/notebook-for-lesson-4-mle)
* [Notes from Sebasti√°n Ayala Ruano](https://github.com/sayalaruano/100DaysOfMLCode/blob/main/Classification/Notes/NotesDay14.md)
* [Notes from Alvaro Navas](https://github.com/ziritrion/ml-zoomcamp/blob/main/notes/04_01_classification_eval_metrics.md)
* [Notes from froukje](https://github.com/froukje/ml-zoomcamp/blob/main/week4/Lecture_4_metrics.ipynb)
* [Notes from Hareesh Tummala](https://github.com/tummala-hareesh/ml_zoomcamp_ht/blob/main/notes/week-4-notes.md)
* [Notes from Memoona Tahira](https://github.com/MemoonaTahira/MLZoomcamp2022/tree/main/Notes/Week_4%20-evaluation_metrics_for_ML_model)
* [Notes from Peter Ernicke](https://knowmledge.com/category/courses/ml-zoomcamp/evaluation-metrics/)
* [Notes from Kemal Dahha](https://github.com/kemaldahha/machine-learning-course/blob/main/week_4_notes.ipynb)
* Add your notes here

# Homework 4 - Evaluation Metrics for Classification

This homework focuses on evaluation metrics for binary classification problems. All solutions can be found in the [homework.ipynb](homework.ipynb) notebook.

## Contents

The notebook contains solutions for:
- ROC AUC analysis
- Precision and Recall calculations
- F1 Score optimization
- Cross-validation implementation
- Model parameter tuning (C values)

## Key Results

The notebook demonstrates:
- Confusion matrix calculations
- Precision-Recall curve analysis
- Optimal threshold finding for F1 score
- Cross-validation with different model configurations

## Running the Solutions

To run the solutions:
1. Make sure you have all required dependencies installed
2. The dataset will be automatically downloaded when running the notebook
3. Run all cells in `homework.ipynb` sequentially

## Dependencies

- Python 3
- NumPy
- Pandas
- Scikit-learn
- Matplotlib
- Seaborn

## Dataset

The notebook uses the lead scoring dataset, which is automatically downloaded from:
https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv

